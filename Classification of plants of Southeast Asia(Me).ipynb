{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport pandas as pd\nimport plotly.graph_objects as go\nimport re\nimport numpy as np\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nfrom keras_preprocessing import image\nfrom tensorflow.keras import callbacks\nimport os \nimport shutil\nimg_height=224\nimg_width=224","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:52:20.8202Z","iopub.execute_input":"2022-04-09T10:52:20.820899Z","iopub.status.idle":"2022-04-09T10:52:20.826907Z","shell.execute_reply.started":"2022-04-09T10:52:20.820862Z","shell.execute_reply":"2022-04-09T10:52:20.826031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# traning data handle\ndata_path='../input/classification-of-plants-of-southeast-asia/bali-26_train/bali-26_train'\ndata=[]\nfor folder_path in glob.glob('{}/*'.format(data_path)):\n    label=folder_path.split('/')[-1]\n    for file_path in glob.glob('{}/*.jpg'.format(folder_path)):\n        data.append([file_path,label])\ndf = pd.DataFrame(columns=['filepath', 'label'], data=data)\ndf.to_csv('data.csv',index=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:52:20.848867Z","iopub.execute_input":"2022-04-09T10:52:20.849098Z","iopub.status.idle":"2022-04-09T10:52:27.016026Z","shell.execute_reply.started":"2022-04-09T10:52:20.84907Z","shell.execute_reply":"2022-04-09T10:52:27.015298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# draw a histogram of the labels\nfig=go.Figure(data=[go.Histogram(x=df['label'],xbins=dict(start=0,end=26,size=1))])\nfig.update_layout(title='Histogram of labels')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:52:27.017939Z","iopub.execute_input":"2022-04-09T10:52:27.018429Z","iopub.status.idle":"2022-04-09T10:52:27.308791Z","shell.execute_reply.started":"2022-04-09T10:52:27.018392Z","shell.execute_reply":"2022-04-09T10:52:27.308181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_size= 1400\n\n\nsample_list=[]\ngroups=df.groupby('label')\nfor label in df['label'].unique():                 \n    group=groups.get_group(label)\n    sample_count=len(group)    \n    if sample_count> max_size:\n        samples=group.sample(max_size, replace=False, weights=None, random_state=123, axis=0).reset_index(drop=True)\n    else:\n        samples=group.sample(frac=1.0, replace=False, random_state=123, axis=0).reset_index(drop=True)\n    sample_list.append(samples)\ndf=pd.concat(sample_list, axis=0).reset_index(drop=True)\n# draw a histogram of the labels\nfig=go.Figure(data=[go.Histogram(x=df['label'],xbins=dict(start=0,end=26,size=1))])\nfig.update_layout(title='Histogram of labels')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:52:27.309684Z","iopub.execute_input":"2022-04-09T10:52:27.309929Z","iopub.status.idle":"2022-04-09T10:52:27.502316Z","shell.execute_reply.started":"2022-04-09T10:52:27.309895Z","shell.execute_reply":"2022-04-09T10:52:27.501529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"working_dir=r'./'\naug_dir=os.path.join(working_dir, 'aug')\nif os.path.isdir(aug_dir):\n    shutil.rmtree(aug_dir)\nos.mkdir(aug_dir)\nfor label in df['label'].unique():\n    dir_path=os.path.join(aug_dir,label)    \n    os.mkdir(dir_path)\nprint(os.listdir(aug_dir))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:52:27.504426Z","iopub.execute_input":"2022-04-09T10:52:27.504684Z","iopub.status.idle":"2022-04-09T10:52:27.516037Z","shell.execute_reply.started":"2022-04-09T10:52:27.504651Z","shell.execute_reply":"2022-04-09T10:52:27.515254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = max_size\ngen=ImageDataGenerator(horizontal_flip=True,\n                       rotation_range=20,\n                       width_shift_range=.2,\n                       height_shift_range=.2,\n                       zoom_range=.2)\ngroups=df.groupby('label')\nfor label in df['label'].unique():  # for every class            \n    group=groups.get_group(label)  # a dataframe holding only rows with the specified label \n    sample_count=len(group)   # determine how many samples there are in this class  \n    if sample_count< target: # if the class has less than target number of images\n        aug_img_count=0\n        delta=target-sample_count  # number of augmented images to create\n        target_dir=os.path.join(aug_dir, label)  # define where to write the images    \n        aug_gen=gen.flow_from_dataframe( group,  x_col='filepath', y_col=None, target_size=(img_height,img_width), class_mode=None, batch_size=1,\n                                         shuffle=False, save_to_dir=target_dir, save_prefix='aug-',save_format='jpg')\n        while aug_img_count<delta:\n            images=next(aug_gen)            \n            aug_img_count += len(images) ","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:52:27.517368Z","iopub.execute_input":"2022-04-09T10:52:27.517606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_fpaths=[]\naug_labels=[]\nclasslist=os.listdir(aug_dir)\nfor klass in classlist:\n    classpath=os.path.join(aug_dir, klass)     \n    flist=os.listdir(classpath)    \n    for f in flist:        \n        fpath=os.path.join(classpath,f)         \n        aug_fpaths.append(fpath)\n        aug_labels.append(klass)\nFseries=pd.Series(aug_fpaths, name='filepath')\nLseries=pd.Series(aug_labels, name='label')\naug_df=pd.concat([Fseries, Lseries], axis=1)\nprint ('length of aug_df\" ', len(aug_df))\nbalance_df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\nbalance_df=balance_df.sample(frac=1.0, replace=False, random_state=123, axis=0).reset_index(drop=True)\nprint ('length of df is: ', len(df)) \n\n# draw a histogram of the labels\nfig=go.Figure(data=[go.Histogram(x=balance_df['label'],xbins=dict(start=0,end=26,size=1))])\nfig.update_layout(title='Histogram of labels')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for gpu in tf.config.experimental.list_physical_devices('GPU'):    \n    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n    tf.compat.v2.config.experimental.set_memory_growth(gpu, True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ImageDataGenerator\ntrain_data_dir='../input/classification-of-plants-of-southeast-asia/bali-26_train/bali-26_train'\nbatch_size=64\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    fill_mode='nearest',\n    horizontal_flip=True,\n    validation_split=0.05 # set validation split\n                                  ) \n# preview the train_datagen image\npic=image.load_img('../input/classification-of-plants-of-southeast-asia/bali-26_train/bali-26_train/durian/10022.jpg')\npic=pic.resize((img_height,img_width))\npic_arr=image.img_to_array(pic)\npic_arr=pic_arr.reshape((1,)+pic_arr.shape)\nnum_img=4\nfig=plt.figure(figsize=(num_img,num_img))\nfig.set_size_inches(18.5, 10.5)\ncount=0\nfor b in train_datagen.flow(pic_arr):\n    plt.subplot(num_img,num_img,count+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(b[0])\n    count+=1\n    if count==num_img*num_img:\n        break\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ntrain_generator = train_datagen.flow_from_dataframe(\n    balance_df,\n    x_col='filepath', y_col='label',\n    target_size=(img_height, img_width),\n    batch_size=batch_size, class_mode='categorical',\n    shuffle=True,\n    subset='training')  # set as training data\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n    balance_df,\n    x_col='filepath', y_col='label',\n    target_size=(img_height, img_width),\n    batch_size=batch_size, class_mode='categorical',\n    subset='validation')  # set as validation data\n\n\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_generator.samples,len(train_generator))\nprint(train_generator.samples//batch_size)\nprint(type(train_generator))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xem thu data\nimg, label = train_generator.next()\nprint(img.shape)\nprint(label.shape)\nplt.imshow(img[0])\nprint(labels[np.argmax(label[0])])\nprint(np.min(img),np.max(img))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preview image\nfig=plt.figure(figsize=(5,5))\nfig.set_size_inches(18.5, 10.5)\n\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(img[i%batch_size])\n    plt.xlabel(labels[np.argmax(label[i%batch_size])])\n    if (i%batch_size==0):\n        img, label = train_generator.next()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications  import InceptionResNetV2\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    resnet = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(224,224,3),pooling='avg')\n    output = resnet.layers[-1].output\n    output = tf.keras.layers.Flatten()(output)\n    resnet = Model(resnet.input, output)\n    set_trainable = False\n    res_name = []\n    for layer in resnet.layers:\n        res_name.append(layer.name)\n    for layer in resnet.layers:\n        if layer.name in res_name[-447:]:\n            set_trainable = True\n        if set_trainable:\n            layer.trainable = True\n        else:\n            layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createModel():\n    model = models.Sequential()\n    model.add(resnet)\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.4))\n    # 26 category\n    model.add(Dense(26,activation='softmax'))\n    model.summary()\n    model.compile(optimizer =\"adam\",                \n                  steps_per_execution = 50,\n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n    return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=createModel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## let train =))\nepochs=200\nhistory = model.fit(train_generator,\n                          epochs=epochs,\n                          validation_data=validation_generator,\n                     callbacks=[\n                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2,verbose=1,restore_best_weights=True),\n                        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1, min_lr=0.00001)\n                    ]\n                        )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # summarize history \n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs_range = range(len(acc))\n\n    fig=plt.figure(figsize=(8, 8))\n    fig.set_size_inches(18.5, 10.5)\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.show()\nexcept:\n    pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict the test for submission\nfolder_path='../input/classification-of-plants-of-southeast-asia/bali-26_test/bali-26_test'\nimages= glob.glob('{}/*.jpg'.format(folder_path))\nsubmissions=[]\n\nfor image_file in images:\n    img = image.load_img(image_file, target_size=(img_height, img_width))\n    x = image.img_to_array(img)\n    x = x / 255.0\n    x = x.reshape((1,)+x.shape)\n    predict=model.predict(x)[0]\n    \n    idd=image_file.split('/')[-1]\n    category=labels[np.argmax(predict)]\n    submissions.append([idd,category])\ndf = pd.DataFrame(columns=['id', 'category'], data=submissions)\ndf.to_csv('submission.csv',index=False)\nplt.imshow(img)\nprint(predict)\nprint(category)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}